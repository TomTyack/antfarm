# Ralph loop (https://github.com/snarktank/ralph) — each agent runs in a fresh
# session with clean context. Memory persists via git history and progress files.
id: feature-dev
name: Feature Development Workflow
version: 5
description: |
  Story-based execution pipeline. Planner decomposes tasks into user stories.
  Setup prepares the environment and establishes baseline.
  Developer implements each story (with tests) in a fresh session. Verifier checks each story.
  Then integration/E2E testing, PR creation, and code review.

polling:
  model: default
  timeoutSeconds: 120

agents:
  - id: planner
    name: Planner
    role: analysis
    description: Decomposes tasks into ordered user stories.
    workspace:
      baseDir: agents/planner
      files:
        AGENTS.md: agents/planner/AGENTS.md
        SOUL.md: agents/planner/SOUL.md
        IDENTITY.md: agents/planner/IDENTITY.md
        cc-dev-database-query.md: ../../skills/content-craft/cc-dev-database-query.md
        cc-prompt-management.md: ../../skills/content-craft/cc-prompt-management.md
        cc-sanity-tree-references.md: ../../skills/content-craft/cc-sanity-tree-references.md
        react-best-practices.md: ../../skills/content-craft/react-best-practices.md

  - id: setup
    name: Setup
    role: coding
    description: Prepares environment, creates branch, establishes baseline.
    workspace:
      baseDir: agents/setup
      files:
        AGENTS.md: ../../agents/shared/setup/AGENTS.md
        SOUL.md: ../../agents/shared/setup/SOUL.md
        IDENTITY.md: ../../agents/shared/setup/IDENTITY.md
        cc-dev-start-stop.md: ../../skills/content-craft/cc-dev-start-stop.md
        cc-dev-install-deps.md: ../../skills/content-craft/cc-dev-install-deps.md

  - id: developer
    name: Developer
    role: coding
    description: Implements features, writes tests, creates PRs.
    workspace:
      baseDir: agents/developer
      files:
        AGENTS.md: agents/developer/AGENTS.md
        SOUL.md: agents/developer/SOUL.md
        IDENTITY.md: agents/developer/IDENTITY.md
<<<<<<< Updated upstream
=======
        cc-super-dev-prompt.md: quality-gates/cc-super-dev-prompt.md
        cc-nextjs-serverside.md: quality-gates/cc-nextjs-serverside.md
        cc-frontend-dev.md: ../../skills/content-craft/cc-frontend-dev.md
        cc-auth-server.md: ../../skills/content-craft/cc-auth-server.md
        react-best-practices.md: ../../skills/content-craft/react-best-practices.md
>>>>>>> Stashed changes

  - id: verifier
    name: Verifier
    role: verification
    description: Quick sanity check - did developer actually do the work?
    workspace:
      baseDir: agents/verifier
      skills:
        - agent-browser
      files:
        AGENTS.md: ../../agents/shared/verifier/AGENTS.md
        SOUL.md: ../../agents/shared/verifier/SOUL.md
        IDENTITY.md: ../../agents/shared/verifier/IDENTITY.md
        cc-super-dev-prompt.md: quality-gates/cc-super-dev-prompt.md
        cc-nextjs-serverside.md: quality-gates/cc-nextjs-serverside.md
        react-best-practices.md: ../../skills/content-craft/react-best-practices.md

<<<<<<< Updated upstream
=======
  - id: quality-gate
    name: Quality Gate
    role: refactoring
    description: Runs code and refactors according to architectural patterns before testing.
    workspace:
      baseDir: agents/quality-gate
      files:
        AGENTS.md: agents/quality-gate/AGENTS.md
        SOUL.md: agents/quality-gate/SOUL.md
        IDENTITY.md: agents/quality-gate/IDENTITY.md
        cc-nextjs-serverside.md: quality-gates/cc-nextjs-serverside.md
        cc-super-dev-prompt.md: quality-gates/cc-super-dev-prompt.md
        react-best-practices.md: ../../skills/content-craft/react-best-practices.md
        cc-auth-server.md: ../../skills/content-craft/cc-auth-server.md

>>>>>>> Stashed changes
  - id: tester
    name: Tester
    role: testing
    description: Integration and E2E testing using headed Chrome browser.
    workspace:
      baseDir: agents/tester
      files:
        AGENTS.md: agents/tester/AGENTS.md
        SOUL.md: agents/tester/SOUL.md
        IDENTITY.md: agents/tester/IDENTITY.md
        content-craft-browser-tester.md: quality-gates/content-craft-browser-tester.md
        cc-dev-start-stop.md: ../../skills/content-craft/cc-dev-start-stop.md
        cc-dev-api-testing.md: ../../skills/content-craft/cc-dev-api-testing.md

  - id: reviewer
    name: Reviewer
    role: analysis
    description: Reviews PRs, requests changes or approves.
    workspace:
      baseDir: agents/reviewer
      skills:
        - agent-browser
      files:
        AGENTS.md: agents/reviewer/AGENTS.md
        SOUL.md: agents/reviewer/SOUL.md
        IDENTITY.md: agents/reviewer/IDENTITY.md
        cc-super-dev-prompt.md: quality-gates/cc-super-dev-prompt.md
        cc-nextjs-serverside.md: quality-gates/cc-nextjs-serverside.md
        react-best-practices.md: ../../skills/content-craft/react-best-practices.md

steps:
  - id: plan
    agent: planner
    input: |
      Decompose the following task into ordered user stories for autonomous execution.

      TASK:
      {{task}}

      Available skills (read these for domain knowledge):
      - cc-dev-database-query.md: How to query the PostgreSQL database (schema, tables)
      - cc-prompt-management.md: Prompt system architecture (prompts, variables, chains)
      - cc-sanity-tree-references.md: Sanity CMS hierarchy (businesses, categories, articles)
      - react-best-practices.md: React/Next.js performance patterns (for sizing stories)

      Instructions:
      1. Explore the codebase to understand the stack, conventions, and patterns
      2. Read relevant skills above to understand the domain architecture
      3. Break the task into small user stories (max 20)
      4. Order by dependency: schema/DB first, backend, frontend, integration
      4. Each story must fit in one developer session (one context window)
      5. Every acceptance criterion must be mechanically verifiable
      6. Always include "Typecheck passes" as the last criterion in every story
      7. Every story MUST include test criteria — "Tests for [feature] pass"
      8. The developer is expected to write tests as part of each story

      Reply with:
      STATUS: done
      REPO: /path/to/repo
      BRANCH: feature-branch-name
      STORIES_JSON: [ ... array of story objects ... ]
    expects: "STATUS: done"
    max_retries: 3
    retry_delay_ms: 600000
    on_fail:
      escalate_to: human

  - id: setup
    agent: setup
    input: |
      Prepare the development environment for this feature.

      TASK:
      {{task}}

      REPO: {{repo}}
      BRANCH: {{branch}}

      Instructions:
      1. cd into the repo
<<<<<<< Updated upstream
      2. Create the feature branch (git checkout -b {{branch}})
      3. Read package.json, CI config, test config to understand the build/test setup
      4. Ensure .gitignore exists — if missing, create one appropriate for the detected stack (must include .env, node_modules/, *.key, *.pem at minimum)
      5. Run the build to establish a baseline
      6. Run the tests to establish a baseline
      7. Report what you found
=======
      2. git fetch origin && git checkout develop && git pull
      3. Create the feature branch: git checkout -b {{branch}}
      4. This is a pnpm monorepo (use `corepack pnpm`):
         - Frontend: apps/web (Next.js)
         - Backend: apps/api (Python FastAPI with Poetry)
      5. Build: corepack pnpm --recursive run build
      6. Frontend tests: corepack pnpm --filter web run test
      7. Backend tests: cd apps/api && poetry run pytest
      8. Start services: ./stop-all.sh && sleep 5 && ./start-all.sh
      9. Monitor logs: ./monitor-logs.sh
>>>>>>> Stashed changes

      Reply with:
      STATUS: done
      BUILD_CMD: corepack pnpm --recursive run build
      TEST_CMD: corepack pnpm --filter web run test && cd apps/api && poetry run pytest
      CI_NOTES: <brief CI notes>
      BASELINE: <baseline status>
    expects: "STATUS: done"
    max_retries: 3
    retry_delay_ms: 600000
    on_fail:
      escalate_to: human

  - id: implement
    agent: developer
    type: loop
    loop:
      over: stories
      completion: all_done
      fresh_session: true
      verify_each: true
      verify_step: verify
    input: |
      Implement the following user story. You are working on ONE story in a fresh session.

      TASK (overall):
      {{task}}

      REPO: {{repo}}
      BRANCH: {{branch}}
      BUILD_CMD: {{build_cmd}}
      TEST_CMD: {{test_cmd}}

      CURRENT STORY:
      {{current_story}}

      COMPLETED STORIES:
      {{completed_stories}}

      STORIES REMAINING: {{stories_remaining}}

      VERIFY FEEDBACK (if retrying):
      {{verify_feedback}}

      PROGRESS LOG:
      {{progress}}

      Available skills (read these before coding):
      - cc-super-dev-prompt.md: Development standards and Implementation Chamber
      - cc-nextjs-serverside.md: Next.js Server Component architecture
      - cc-frontend-dev.md: UI patterns and Terminal Elegance design system
      - cc-auth-server.md: Server-side authentication (getServerUser, Supabase)
      - react-best-practices.md: React performance optimization (40+ rules)

      Instructions:
<<<<<<< Updated upstream
      1. Read progress-{{run_id}}.txt — especially the Codebase Patterns section
      2. Pull latest on the branch
      3. Implement this story only
      4. Write tests for this story's functionality
      5. Run typecheck / build
      6. Run tests to confirm they pass
      7. Commit: feat: {{current_story_id}} - {{current_story_title}}
      8. Append to progress-{{run_id}}.txt
      9. Update Codebase Patterns if you found reusable patterns
=======
      1. Read cc-super-dev-prompt.md — enter the Implementation Chamber
      2. Read progress.txt — especially the Codebase Patterns section
      3. If UI work, read cc-frontend-dev.md for design system patterns
      4. If auth, read cc-auth-server.md for correct auth patterns
      5. Read cc-nextjs-serverside.md for Server Component architecture
      6. Build mental model BEFORE coding — let the solution emerge
      7. Generate 3-5 verification questions and answer them adversarially
      8. Pull latest on the branch
      9. Implement this story only (following your verified approach)
      10. Write tests for this story's functionality
      11. Run typecheck / build
      12. Run tests to confirm they pass
      13. Commit: feat: {{current_story_id}} - {{current_story_title}}
      14. Append to progress.txt
      15. Update Codebase Patterns if you found reusable patterns
>>>>>>> Stashed changes

      Reply with:
      STATUS: done
      CHANGES: what you implemented
      TESTS: what tests you wrote
    expects: "STATUS: done"
    max_retries: 3
    retry_delay_ms: 600000
    on_fail:
      escalate_to: human

  - id: verify
    agent: verifier
    input: |
      Verify the developer's work on this story.

      TASK (overall):
      {{task}}

      REPO: {{repo}}
      BRANCH: {{branch}}
      CHANGES: {{changes}}
      TEST_CMD: {{test_cmd}}

      CURRENT STORY:
      {{current_story}}

      PROGRESS LOG:
      {{progress}}

      Check:
      1. Code exists (not just TODOs or placeholders)
      2. Each acceptance criterion for the story is met
      3. Tests were written for this story's functionality
      4. Tests pass (run {{test_cmd}})
      5. No obvious incomplete work
      6. Typecheck passes

<<<<<<< Updated upstream
      ## Visual Verification (Frontend Changes)
      Has frontend changes: {{has_frontend_changes}}

      If {{has_frontend_changes}} is 'true', you MUST also perform visual verification:
      1. Use the agent-browser skill to visually inspect the changed UI
      2. Open the changed HTML file directly (file:// URL) or spin up a local dev server if the project requires one
      3. Take a screenshot of the rendered page
      4. Visually confirm:
         - Layout renders correctly (no broken/overlapping elements)
         - Styling is applied as expected (colors, fonts, spacing)
         - All visible elements from the story are present and properly positioned
         - No missing images, icons, or visual assets
         - Text is readable and not clipped or hidden
      5. A visual PASS means: the page renders without broken layout, missing elements, or overlapping content
      6. A visual FAIL means: broken layout, missing/invisible elements, overlapping or misaligned content, unstyled raw HTML, or obvious rendering errors
      7. Include your visual findings in VERIFIED output

      If {{has_frontend_changes}} is 'false', skip visual verification entirely.
=======
      Code Quality Standards (read cc-super-dev-prompt.md for full details):
      - Functions/methods: max 45 lines (strict)
      - Code files: max 500 lines (strict)
      - Component files: max 300 lines
      - Component functions: max 80 lines
      - Max nesting depth: 3 levels
      - No code duplication (DRY enforced)
      - Single responsibility per function
      Use wc -l and grep to measure programmatically.

      Next.js Architecture (read cc-nextjs-serverside.md for full details):
      - Pages and layouts MUST be Server Components (no 'use client')
      - 'use client' only on leaf components needing interactivity
      - Data fetching in Server Components, NOT useEffect
      - Use serverFetch() and getServerUser() — no custom fetch patterns
      - Props passed to Client Components must be serializable
      - server-only package protects sensitive server code
>>>>>>> Stashed changes

      Reply with:
      STATUS: done
      VERIFIED: What you confirmed

      Or if incomplete:
      STATUS: retry
      ISSUES:
      - What's missing or incomplete
    expects: "STATUS: done"
    on_fail:
      retry_step: implement
      max_retries: 3
      retry_delay_ms: 600000
      on_exhausted:
        escalate_to: human

<<<<<<< Updated upstream
=======
  - id: quality-gate
    agent: quality-gate
    input: |
      Quality gate: Run the code and refactor according to architectural patterns.

      TASK:
      {{task}}

      REPO: {{repo}}
      BRANCH: {{branch}}
      CHANGES: {{changes}}
      BUILD_CMD: {{build_cmd}}

      PROGRESS LOG:
      {{progress}}

      Available skills (read these for quality review):
      - cc-nextjs-serverside.md: Next.js Server Component architecture
      - cc-super-dev-prompt.md: Code quality standards (size limits, complexity)
      - react-best-practices.md: React performance (40+ rules)
      - cc-auth-server.md: Auth patterns (getServerUser, Supabase)

      Your job:
      1. Read cc-nextjs-serverside.md for Next.js architectural patterns
      2. Read cc-super-dev-prompt.md for code quality size limits
      3. Read react-best-practices.md for performance anti-patterns
      4. Run the code to verify it actually works
      5. Review the implementation against architectural patterns:
         - Server Components vs Client Components placement
         - Data fetching patterns (server-side vs client-side)
         - Component boundaries and serialization
         - Use of established utilities (serverFetch, getServerUser)
      4. Refactor any violations:
         - Move 'use client' to leaf components
         - Move data fetching to server components
         - Fix serialization issues
         - Ensure typecheck still passes after refactoring
      5. Run build to confirm no regressions
      6. Commit refactorings: refactor: architectural improvements

      Reply with:
      STATUS: done
      REFACTORINGS: What patterns you fixed (or "none needed")
      
      Or if blocking issues found:
      STATUS: retry
      ISSUES:
      - Architectural violations that need developer attention
    expects: "STATUS: done"
    max_retries: 3
    retry_delay_ms: 600000
    on_fail:
      retry_step: implement
      max_retries: 3
      retry_delay_ms: 600000
      on_exhausted:
        escalate_to: human

>>>>>>> Stashed changes
  - id: test
    agent: tester
    input: |
      Integration and E2E browser testing of the implementation.

      TASK:
      {{task}}

      REPO: {{repo}}
      BRANCH: {{branch}}
      CHANGES: {{changes}}
      BUILD_CMD: {{build_cmd}}
      TEST_CMD: {{test_cmd}}

      PROGRESS LOG:
      {{progress}}

      Read content-craft-browser-tester.md for full browser testing instructions.

      Your job:
      1. Run the full test suite ({{test_cmd}}) to confirm everything passes together
      2. Look for integration issues between stories

      Browser testing with headed Chrome (REQUIRED for UI changes):
      3. Ensure services are running: ./stop-all.sh && sleep 5 && ./start-all.sh
      4. Start headed Chrome with Xvfb:
         xvfb-run google-chrome-stable --remote-debugging-port=9222 --no-first-run --no-default-browser-check --user-data-dir=/tmp/chrome-test-profile &
         sleep 3
      5. Login to http://localhost:3000/login:
         - Email: contentcraft@email.ghostinspector.com
         - Password: Contentsurf251!
      6. Use Chrome DevTools MCP tools to navigate and test the feature:
         - take_snapshot before interacting (use uids from snapshot)
         - click, fill, press_key to interact with elements
         - wait_for after page transitions
         - take_screenshot to document states
      7. Check for errors: list_console_messages, list_network_requests
      8. Run Playwright E2E tests with headed Chrome:
         xvfb-run corepack pnpm --filter web exec playwright test --headed --project=chromium

      Cross-cutting checks:
      9. Error handling across features
      10. Edge cases: empty inputs, special characters
      11. Verify the overall feature works as a cohesive whole

      Reply with:
      STATUS: done
      RESULTS: What you tested and the outcomes
      TEST_RESULTS:
      - Test name: PASS/FAIL - details
      CONSOLE_ERRORS: none (or list)
      SCREENSHOTS: list of screenshots taken

      Or if issues found:
      STATUS: retry
      FAILURES:
      - Specific test failures or bugs found
    expects: "STATUS: done"
    on_fail:
      retry_step: implement
      max_retries: 3
      retry_delay_ms: 600000
      on_exhausted:
        escalate_to: human

  - id: pr
    agent: developer
    input: |
      Create a pull request for your changes.

      TASK:
      {{task}}

      REPO: {{repo}}
      BRANCH: {{branch}}
      CHANGES: {{changes}}
      RESULTS: {{results}}

      PROGRESS LOG:
      {{progress}}

      PR title format: feat: TICKET-ID - brief description of the feature
      If the TASK field contains a Monday.com ticket ID (e.g. FEAT-001, BUG-025, or similar),
      extract it and include it in the PR title.
      Example: feat: FEAT-012 - Add dark mode toggle to dashboard

      Create a PR with:
      - Title including the ticket ID as shown above
      - Description explaining what and why
      - Reference to what was tested
      - Monday.com ticket reference if available

      Use: gh pr create

      Reply with:
      STATUS: done
      PR: URL to the pull request
    expects: "STATUS: done"
    on_fail:
      escalate_to: human

  - id: review
    agent: reviewer
    input: |
      Review the pull request.

      PR: {{pr}}
      TASK: {{task}}
      CHANGES: {{changes}}

      PROGRESS LOG:
      {{progress}}

      Available skills (read these for review standards):
      - cc-super-dev-prompt.md: Code quality standards (size limits, complexity, DRY)
      - cc-nextjs-serverside.md: Next.js Server Component architecture
      - react-best-practices.md: React performance optimization patterns

      Review for:
      - Code quality standards (read cc-super-dev-prompt.md): function/file size limits, nesting, DRY
      - Next.js architecture (read cc-nextjs-serverside.md): Server Components, leaf Client Components
      - React performance (read react-best-practices.md): no waterfalls, no barrel imports, proper memoization
      - Potential bugs or issues
      - Test coverage
      - Follows project conventions

      Use: gh pr view, gh pr diff to read the PR.

      IMPORTANT: Post your review to the PR on GitHub using:
      - If approving: gh pr review <number> --approve --body "your review summary"
      - If requesting changes: gh pr review <number> --request-changes --body "your feedback"

      ## Visual Review (Frontend Changes)
      Has frontend changes: {{has_frontend_changes}}

      If {{has_frontend_changes}} is 'true', you MUST also perform a visual design review:
      1. Check out the branch: git checkout {{branch}}
      2. Use the agent-browser skill to open the changed page (file:// URL or local dev server)
      3. Take a screenshot of the rendered page
      4. Evaluate visual polish and design quality:
         - Does the UI look polished and intentional, not rough or placeholder-quality?
         - Are colors, typography, and spacing consistent with the rest of the project?
         - Is the layout visually balanced and well-aligned?
         - Do interactive elements look clickable/tappable?
         - Is the overall design cohesive — does it feel like part of the same product?
      5. This is a DESIGN review, not a structural check — the verify step already confirmed elements render. You are checking whether the result looks GOOD.
      6. Include your visual design assessment in the review output

      If {{has_frontend_changes}} is 'false', skip visual review entirely.

      If changes needed, add comments to the PR explaining what needs to change.

      Reply with:
      STATUS: done
      DECISION: approved

      Or if changes needed:
      STATUS: retry
      DECISION: changes_requested
      FEEDBACK:
      - What needs to change
    expects: "STATUS: done"
    on_fail:
      retry_step: implement
      max_retries: 3
      on_exhausted:
        escalate_to: human
